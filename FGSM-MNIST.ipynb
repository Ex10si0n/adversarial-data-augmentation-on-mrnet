{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a simple CNN architecture for adversarial training\n",
    "Before we can perform an adversarial attack, we first need to implement our CNN architecture.\n",
    "\n",
    "Once our architecture is implemented, weâ€™ll train it on the MNIST dataset, evaluate it, generate a set of adversarial images using the FGSM, and re-evaluate it, thereby demonstrating the impact adversarial images have on accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MSE\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class SimpleCNN:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model\n",
    "\n",
    "def generate_image_adversary(model, image, label, eps=2 / 255.0):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        pred = model(image)\n",
    "        loss = MSE(label, pred)\n",
    "        gradient = tape.gradient(loss, image)\n",
    "        sign = tf.sign(gradient)\n",
    "        adversary = (image + (sign * eps)).numpy()\n",
    "        return adversary"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Target Model\n",
    "\n",
    "This block need to run once before Applying FGSM Attack"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "(60000, 28, 28, 1)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cv/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 6s 7ms/step - loss: 0.2043 - accuracy: 0.9391 - val_loss: 0.0911 - val_accuracy: 0.9714\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0825 - accuracy: 0.9751 - val_loss: 0.0498 - val_accuracy: 0.9833\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0637 - accuracy: 0.9802 - val_loss: 0.0489 - val_accuracy: 0.9856\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.0368 - val_accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0430 - accuracy: 0.9864 - val_loss: 0.0346 - val_accuracy: 0.9887\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0345 - accuracy: 0.9886 - val_loss: 0.0331 - val_accuracy: 0.9893\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0426 - val_accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0415 - val_accuracy: 0.9870\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0365 - val_accuracy: 0.9884\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0351 - val_accuracy: 0.9886\n",
      "[INFO] loss: 0.0351, acc: 0.9886\n",
      "INFO:tensorflow:Assets written to: saved_model/TargetCNN/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "\n",
    "# add a channel dimension to the images\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "# one-hot encode our labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=1e-3)\n",
    "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# train the simple CNN on MNIST\n",
    "print(\"[INFO] training network...\")\n",
    "print(trainX.shape)\n",
    "model.fit(trainX, trainY,\n",
    "          validation_data=(testX, testY),\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          verbose=1)\n",
    "\n",
    "# make predictions on the testing set for the model trained on\n",
    "# non-adversarial images\n",
    "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
    "print(\"[INFO] loss: {:.4f}, acc: {:.4f}\".format(loss, acc))\n",
    "model.save(\"saved_model/TargetCNN\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def FGSM_train(model, ratio, eps):\n",
    "\n",
    "    a_trainX = []\n",
    "    a_trainY = []\n",
    "    for i in np.random.choice(np.arange(0, len(trainX)), size=(int(len(trainX) * ratio),)):\n",
    "        # grab the current image and label\n",
    "        image = trainX[i]\n",
    "        label = trainY[i]\n",
    "        # generate an image adversary for the current image and make\n",
    "        # a prediction on the adversary\n",
    "        adversary = generate_image_adversary(model, image.reshape(1, 28, 28, 1), label, eps=eps)\n",
    "        pred = model.predict(adversary)\n",
    "\n",
    "        a_trainX.append(adversary)\n",
    "        a_trainY.append(pred)\n",
    "\n",
    "\n",
    "        # print(pred.argmax(), label.argmax())\n",
    "        # scale both the original image and adversary to the range\n",
    "        # [0, 255] and convert them to an unsigned 8-bit integers\n",
    "        adversary = adversary.reshape((28, 28)) * 255\n",
    "        adversary = np.clip(adversary, 0, 255).astype(\"uint8\")\n",
    "        image = image.reshape((28, 28)) * 255\n",
    "        image = image.astype(\"uint8\")\n",
    "\n",
    "    a_trainX = np.array(a_trainX)\n",
    "    a_trainY = np.array(a_trainY)\n",
    "\n",
    "    a_trainX = a_trainX.squeeze(axis=1)\n",
    "    a_trainY = a_trainY.squeeze(axis=1)\n",
    "\n",
    "    model.fit(a_trainX, a_trainY,\n",
    "              validation_data=(testX, testY),\n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              verbose=1)\n",
    "    (loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
    "    return loss, acc\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.1777 - accuracy: 0.9587 - val_loss: 0.0420 - val_accuracy: 0.9872\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1622 - accuracy: 0.9649 - val_loss: 0.0430 - val_accuracy: 0.9863\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.1528 - accuracy: 0.9680 - val_loss: 0.0340 - val_accuracy: 0.9886\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.1465 - accuracy: 0.9689 - val_loss: 0.0423 - val_accuracy: 0.9859\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.1358 - accuracy: 0.9732 - val_loss: 0.0399 - val_accuracy: 0.9872\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.1326 - accuracy: 0.9761 - val_loss: 0.0389 - val_accuracy: 0.9874\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.1309 - accuracy: 0.9754 - val_loss: 0.0419 - val_accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.1272 - accuracy: 0.9797 - val_loss: 0.0403 - val_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.1260 - accuracy: 0.9783 - val_loss: 0.0454 - val_accuracy: 0.9849\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.1242 - accuracy: 0.9789 - val_loss: 0.0425 - val_accuracy: 0.9854\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0415 - accuracy: 0.9927 - val_loss: 0.0367 - val_accuracy: 0.9882\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.0461 - accuracy: 0.9907 - val_loss: 0.0358 - val_accuracy: 0.9880\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.0406 - accuracy: 0.9927 - val_loss: 0.0384 - val_accuracy: 0.9870\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0397 - accuracy: 0.9945 - val_loss: 0.0333 - val_accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.0370 - accuracy: 0.9941 - val_loss: 0.0360 - val_accuracy: 0.9872\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0378 - accuracy: 0.9937 - val_loss: 0.0288 - val_accuracy: 0.9908\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0359 - accuracy: 0.9942 - val_loss: 0.0310 - val_accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0360 - accuracy: 0.9947 - val_loss: 0.0328 - val_accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0341 - accuracy: 0.9962 - val_loss: 0.0329 - val_accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0343 - accuracy: 0.9948 - val_loss: 0.0360 - val_accuracy: 0.9879\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0355 - accuracy: 0.9927 - val_loss: 0.0361 - val_accuracy: 0.9887\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.0354 - accuracy: 0.9925 - val_loss: 0.0394 - val_accuracy: 0.9882\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0333 - accuracy: 0.9936 - val_loss: 0.0324 - val_accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0319 - accuracy: 0.9951 - val_loss: 0.0346 - val_accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0327 - accuracy: 0.9946 - val_loss: 0.0342 - val_accuracy: 0.9889\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0322 - accuracy: 0.9942 - val_loss: 0.0355 - val_accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0321 - accuracy: 0.9952 - val_loss: 0.0362 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0299 - accuracy: 0.9952 - val_loss: 0.0316 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0294 - accuracy: 0.9962 - val_loss: 0.0346 - val_accuracy: 0.9877\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0279 - accuracy: 0.9956 - val_loss: 0.0330 - val_accuracy: 0.9886\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0316 - accuracy: 0.9935 - val_loss: 0.0379 - val_accuracy: 0.9882\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.0309 - accuracy: 0.9933 - val_loss: 0.0407 - val_accuracy: 0.9868\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.0299 - accuracy: 0.9947 - val_loss: 0.0349 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.0270 - accuracy: 0.9962 - val_loss: 0.0351 - val_accuracy: 0.9896\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 593s 3s/step - loss: 0.0256 - accuracy: 0.9965 - val_loss: 0.0387 - val_accuracy: 0.9869\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.0261 - accuracy: 0.9958 - val_loss: 0.0332 - val_accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0250 - accuracy: 0.9960 - val_loss: 0.0380 - val_accuracy: 0.9886\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0266 - accuracy: 0.9958 - val_loss: 0.0371 - val_accuracy: 0.9875\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0241 - accuracy: 0.9970 - val_loss: 0.0348 - val_accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0258 - accuracy: 0.9965 - val_loss: 0.0393 - val_accuracy: 0.9874\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "\n",
    "# add a channel dimension to the images\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "# one-hot encode our labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "\n",
    "ratios = [0.2, 0.5, 0.7]\n",
    "eps = [0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "\n",
    "f = open('fgsm-res.csv', 'w')\n",
    "\n",
    "for r in ratios:\n",
    "    for e in eps:\n",
    "        model = tf.keras.models.load_model('saved_model/TargetCNN')\n",
    "        loss, acc = FGSM_train(model, r, e)\n",
    "        f.write('%s, %s\\n' % (loss, acc))\n",
    "\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}